{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacofeldman/Metodos1_JacoboFeldman/blob/main/tarea4/Punto12_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPtxwJkTsv4P",
        "outputId": "1ef94a9c-2d1e-4d6a-bd88-cdd6bc39f152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergio en 5 iteraciones\n",
            "Solución usando Newton-Raphson: [1.77245385 1.77245385]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def F(x):\n",
        "    x1, x2 = x\n",
        "    f1 = np.log(x1**2 + x2**2) - np.sin(x1 * x2) - (np.log(2) + np.log(np.pi))\n",
        "    f2 = np.exp(x1 - x2) + np.cos(x1 * x2)\n",
        "    return np.array([f1, f2])\n",
        "\n",
        "\n",
        "def J(x):\n",
        "    x1, x2 = x\n",
        "    df1_dx1 = (2 * x1) / (x1**2 + x2**2) - x2 * np.cos(x1 * x2)\n",
        "    df1_dx2 = (2 * x2) / (x1**2 + x2**2) - x1 * np.cos(x1 * x2)\n",
        "    df2_dx1 = np.exp(x1 - x2) - x2 * np.sin(x1 * x2)\n",
        "    df2_dx2 = -np.exp(x1 - x2) - x1 * np.sin(x1 * x2)\n",
        "    return np.array([[df1_dx1, df1_dx2], [df2_dx1, df2_dx2]])\n",
        "\n",
        "\n",
        "def newton_raphson(F, J, x0, tol=1e-6, max_iter=100):\n",
        "    x = np.array(x0, dtype=float)\n",
        "    for i in range(max_iter):\n",
        "        Fx = F(x)\n",
        "        if np.linalg.norm(Fx) < tol:\n",
        "            print(f\"Convergio en {i} iteraciones\")\n",
        "            return x\n",
        "        Jx = J(x)\n",
        "        delta_x = np.linalg.solve(Jx, -Fx)\n",
        "        x = x + delta_x\n",
        "    raise ValueError(\"No converge\")\n",
        "\n",
        "\n",
        "x0 = [2, 2]\n",
        "\n",
        "\n",
        "solution_nr = newton_raphson(F, J, x0)\n",
        "print(\"Solución usando Newton-Raphson:\", solution_nr)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def objective(x):\n",
        "    f = F(x)\n",
        "    return 0.5 * np.sum(f**2)\n",
        "\n",
        "\n",
        "def gradient(x):\n",
        "    Jx = J(x)\n",
        "    Fx = F(x)\n",
        "    return np.dot(Jx.T, Fx)\n",
        "\n",
        "\n",
        "def gradient_descent(objective, gradient, x0, lr=0.01, tol=1e-6, max_iter=1000):\n",
        "    x = np.array(x0, dtype=float)\n",
        "    for i in range(max_iter):\n",
        "        grad = gradient(x)\n",
        "        if np.linalg.norm(grad) < tol:\n",
        "            print(f\"Convergio en {i} iteraciones\")\n",
        "            return x\n",
        "        x = x - lr * grad\n",
        "    raise ValueError(\"No converge\")\n",
        "\n",
        "\n",
        "solution_gd = gradient_descent(objective, gradient, x0)\n",
        "print(\"Solución usando descenso de gradiente:\", solution_gd)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oUJfbtNiZge",
        "outputId": "87795e6c-88d9-4369-9159-55c872be6505"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergio en 543 iteraciones\n",
            "Solución usando descenso de gradiente: [1.7724535 1.7724542]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def F2(x):\n",
        "    f1 = 6 * x[0] - 2 * np.cos(x[1] * x[2]) - 1\n",
        "    f2 = 9 * x[1] + np.sqrt(x[0]**2 + np.sin(x[2]) + 1.06) + 0.9\n",
        "    f3 = 60 * x[2] + 3 * np.exp(-x[0] * x[1]) + 10 * np.pi - 3\n",
        "    return np.array([f1, f2, f3])\n",
        "\n",
        "def J2(x):\n",
        "    j11 = 6\n",
        "    j12 = 2 * x[2] * np.sin(x[1] * x[2])\n",
        "    j13 = 2 * x[1] * np.sin(x[1] * x[2])\n",
        "    j21 = x[0] / np.sqrt(x[0]**2 + np.sin(x[2]) + 1.06) if x[0] != 0 else 0\n",
        "    j22 = 9\n",
        "    j23 = np.cos(x[2])\n",
        "    j31 = -3 * x[1] * np.exp(-x[0] * x[1])\n",
        "    j32 = -3 * x[0] * np.exp(-x[0] * x[1])\n",
        "    j33 = 60\n",
        "    return np.array([[j11, j12, j13], [j21, j22, j23], [j31, j32, j33]])\n",
        "\n",
        "\n",
        "def newton_raphson(F, J, x0, tol=1e-9, max_iter=100):\n",
        "    x = np.array(x0, dtype=float)\n",
        "    for i in range(max_iter):\n",
        "        Fx = F(x)\n",
        "        if np.linalg.norm(Fx) < tol:\n",
        "            print(f\"Convergio en {i} iteraciones\")\n",
        "            return x\n",
        "        Jx = J(x)\n",
        "        delta_x = np.linalg.solve(Jx, -Fx)\n",
        "        x = x + delta_x\n",
        "    raise ValueError(\"No converge\")\n",
        "\n",
        "\n",
        "x0 = [0, 0, 0]\n",
        "\n",
        "\n",
        "solution_nr = newton_raphson(F2, J2, x0)\n",
        "print(\"Solución usando Newton-Raphson:\", solution_nr)\n"
      ],
      "metadata": {
        "id": "_vFRP324N9yY",
        "outputId": "4b213ac0-8089-4ea8-bc44-a071624e60cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converged in 5 iterations\n",
            "Solución usando Newton-Raphson: [ 0.49814468 -0.1996059  -0.52882598]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def objective(x):\n",
        "    f = F2(x)\n",
        "    return 0.5 * np.sum(f**2)\n",
        "\n",
        "def gradient(x):\n",
        "    Jx = J2(x)\n",
        "    Fx = F2(x)\n",
        "    return np.dot(Jx.T, Fx)\n",
        "\n",
        "def gradient_descent(objective, gradient, x0, lr=0.0001, tol=1e-6, max_iter=100000):\n",
        "    x = np.array(x0, dtype=float)\n",
        "    for i in range(max_iter):\n",
        "        grad = gradient(x)\n",
        "        if np.linalg.norm(grad) < tol:\n",
        "            print(f\"Convergio en {i} iteraciones\")\n",
        "            return x\n",
        "        x = x - lr * grad\n",
        "    raise ValueError(\"No converge\")\n",
        "\n",
        "x0 = [0, 0, 0]\n",
        "\n",
        "solution_gd = gradient_descent(objective, gradient, x0)\n",
        "print(\"Solución usando descenso de gradiente:\", solution_gd)\n"
      ],
      "metadata": {
        "id": "KmEVFUinTQI1",
        "outputId": "4ed24671-09d3-4a43-bc0f-1c4e7e01ff69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convergio en 4647 iteraciones\n",
            "Solución usando descenso de gradiente: [ 0.49814466 -0.19960589 -0.52882598]\n"
          ]
        }
      ]
    }
  ]
}